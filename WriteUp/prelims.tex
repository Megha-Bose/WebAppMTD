\section{Model and Preliminaries}\label{sec:model}
We consider a repeated game played with two players - a defender (denoted by $\Theta$) and $\tau$ attackers (denoted by $ \Psi = \{\Psi_1, \Psi_2, \dots, \Psi_\tau\}$). At each round (or timestep) of this game, one of these attackers tries to exploit the application set up by the defender. We assume there exists a probability distribution $\cal P$ across these attacker types that determines which attacker attacks at a given time step but this distribution may not always be known to the defender. The defender has a set $\cal C = \{c_1, c_2, \dots c_n\}$ of $n$ configurations that it can deploy. Each configuration has a set of vulnerabilities $\cal V_c = \{e_1, e_2, \dots, e_{|\cal V_c|}\}$ that can be exploited. We define the set of all vulnerabilities by  $N = \bigcup_{c \in C} \cal V_c$. This vulnerability set for each configuration may not be known before hand but we assume that no configuration is perfect i.e. every configuration has some vulnerability. 

At the $t$'th round, the defender chooses a configuration to deploy (denoted by $v_t \in \cal C$) and the attacker of type $f(t)$ (where $f$ is a function that maps a round to the attacker type at that round) chooses a vulnerability to exploit (denoted by $a_t$); the attacker can also choose not to exploit any vulnerability during a turn. Furthermore, we assume that there is a cost incurred when switching between configurations which may not be known a priori but remains constant throughout. The cost incurred by switching from configuration $c$ to configuration $c'$ in the $t$'th round is denoted by $s(c, c') \in (0,1]$. The game is played for $T$ rounds. 

For each vulnerability $e \in N$, for each configuration $c \in \cal C$, for each attacker type $\psi \in \Psi$, we define a reward to the defender at the $t$'th round denoted by $r_t(\psi, e, c)$. The reward $r_t(\psi, e, c) \in [-1, 0)$, if an attacker successfully exploits a vulnerability that the defender's configuration has i.e. $e \in \cal V_c$ and is $0$ otherwise. Note that the different attacker types will result in the defender obtaining different utilities because of the varying attacker capabilities e.g., some attackers may not have the expertise to carry out certain attacks \citep{sailik2016webappmtd}. It is important to note that we do not require the rewards to be constant throughout; they can be stochastic or even adversarial in nature.

We make no assumptions about the attacker strategy since the attacker may not be fully rational. We also do not make assumptions about the attacker utility, since these values will be hard to observe and even harder to find out beforehand. We however assume that the attacker has access to information from the previous rounds and is capable of reconnaissance.

Our goal in this paper is to maximise the total utility that the defender receives, i.e.
\begin{align*}
    \sum_{t=1}^T r_t(\Psi_{f(t)}, a_t, v_t) - s_t(v_{t-1}, v_t)
\end{align*}